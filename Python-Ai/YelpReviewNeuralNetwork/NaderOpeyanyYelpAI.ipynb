{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv \n",
    "import pandas as pd \n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import io\n",
    "from collections.abc import Sequence\n",
    "import shutil\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               business_id  stars  \\\n",
      "0   lyhNDfX8UatlRO5H3Kfccg    5.0   \n",
      "1   ZfKHogPGqQpzgNFSFjfICw    5.0   \n",
      "2   HxegWRjhi7m73mXRI8qQIg    4.0   \n",
      "3   EmJOkTKIwgm7QJbls7hN3w    4.0   \n",
      "4   bZiIIUcpgxh8mpKMDhdqbA    4.0   \n",
      "5   vRrDTIW9IFBO4cc3laazUw    4.0   \n",
      "6   SSdONoTe5UCJjfJ7ZsoMQg    4.0   \n",
      "7   Oj5Seggqo_2FfKSjcAg7yw    3.0   \n",
      "8   FQALxQa69loeORgzbIBBmw    3.0   \n",
      "9   _sS2LBIGNT5NQb6PD1Vtjw    5.0   \n",
      "10  PEnMU_He_qHoCfdoAKmjDQ    4.0   \n",
      "11  W4BJPLCjghJy3_wXjUtQLQ    5.0   \n",
      "12  Un6u2cECyV4nZb_HGZ-uTA    4.0   \n",
      "13  xaTGgwLwFGopzr1VlpBuBw    4.0   \n",
      "14  _gOz7-aHMyGUHOtjDrEv2w    2.0   \n",
      "15  TA1KUSCu8GkWP9w0rmElxw    4.0   \n",
      "16  TA1KUSCu8GkWP9w0rmElxw    4.0   \n",
      "17  Irp5sgl7XASH5ZTw2D47qw    4.0   \n",
      "18  bPmWDBkjBhV11Yk4BipG4Q    4.0   \n",
      "19  J2NLhn_nMK4zeksEr6EE6Q    4.0   \n",
      "20  g4CP3kgH1jTtMn-joxPT0A    4.0   \n",
      "21  Pisoftb2bzA6OkqwppOTTA    2.0   \n",
      "22  zmZ3HkVCeZPBefJJxzdJ7A    4.0   \n",
      "23  bOkLeien1ra8x-7R9E8iYQ    3.0   \n",
      "24  75HV-KqCtn_oHeiLiGlO_w    4.0   \n",
      "25  i9BDFBYcl_PGqrLbQUdMvg    4.0   \n",
      "26  IbuSlumTCNSD-ohMVHfWUA    4.0   \n",
      "27  -TOfMl4hLjH1iOQStV1opw    4.0   \n",
      "28  hrvQyPfec2YqNk9ZknlYig    4.0   \n",
      "29  mOnesB4IF9j6-ZmHoOHOig    4.0   \n",
      "30  mJyvX1Hg9fsrBUgs6gfrig    5.0   \n",
      "31  SwafLjsIK8X4F6md2n6PRw    4.0   \n",
      "32  CoZmZKv2lCYd-UoAsAUobA    4.0   \n",
      "33  q14kE_FYocXv9L4EEYzrzA    3.0   \n",
      "34  9JtY3GKP0QJhYzsEzFugOg    4.0   \n",
      "35  JhSoyaXFf9xUfvow263gug    4.0   \n",
      "36  JdIO0SZKGZPonTuZH8mDXQ    4.0   \n",
      "37  ztlyPlnY5rEh3dM6-kN8BQ    5.0   \n",
      "38  ZX6v0viDJtr_fP7Mt3Gczg    3.0   \n",
      "39  nVM8SLX5Yp3E6NNmL7tAPQ    4.0   \n",
      "40  cTvd8p0R3qgmzobsSIY-cQ    4.0   \n",
      "41  PYDzfxSLUCCwQysbOkFSVA    4.0   \n",
      "42  05pmc_4J0TxoZrft1QxmJg    4.0   \n",
      "43  72PQGMhrEcIuWH-S44TprA    4.0   \n",
      "44  oz882XuZCxajKo64Opgq_Q    3.0   \n",
      "45  DSkmkEUvpVICLd1mjppk5g    5.0   \n",
      "46  AW_dMex_BXFzgBJFxAjDuQ    5.0   \n",
      "47  8gkn6ZKsxdbX2CRZ33UTcQ    5.0   \n",
      "48  8gkn6ZKsxdbX2CRZ33UTcQ    5.0   \n",
      "49  3ZVgig7uux9jVtEZna5NgA    4.0   \n",
      "50  Z4CPbD4a-cR4JR8CH_c3PQ    4.0   \n",
      "\n",
      "                                                 text  \n",
      "0   b'As many people before have said I shall too ...  \n",
      "1   b\"I've used BungoBox for 3 moves now, once for...  \n",
      "2   b\"I mostly eat here at lunch, for the tremendo...  \n",
      "3   b\"Something about this place made me feel like...  \n",
      "4   b'This place is good! You have to stop and try...  \n",
      "5   b'Great photo op if you ever find yourself in ...  \n",
      "6   b\"We were so pleased with everything here.  Th...  \n",
      "7   b\"This place is pretty cool! The ambiance has ...  \n",
      "8   b'The food at Lavaca street bar/surf and turf ...  \n",
      "9   b\"I called WVM on the recommendation of a coup...  \n",
      "10  b\"Great burgers and vibes. The staff is always...  \n",
      "11  b\"Precision Moving Company did an amazing job ...  \n",
      "12  b'It\\'s crazy how establishments on the west c...  \n",
      "13  b\"I've been in Austin for two years and at som...  \n",
      "14  b'When we first arrived at the Coco Key, we we...  \n",
      "15  b\"I have been here twice and have had really g...  \n",
      "16  b'Eating healthy I had the turkey burger it wa...  \n",
      "17  b\"Enjoyed the food, just not so much the order...  \n",
      "18  b'LOVE THIS PLACE!! A true Foodie Favorite!!!!...  \n",
      "19  b\"Stayed there for business the other day. Che...  \n",
      "20  b\"5 stars for the location, it's absolutely wo...  \n",
      "21  b\"Okay, I'm going to get the bad out of the wa...  \n",
      "22  b\"Nothing special but good enough.  I like ano...  \n",
      "23  b'The Cottonwood is mediocre. I ordered the Tw...  \n",
      "24  b\"Great place... delicious tapas and very nice...  \n",
      "25  b\"Excellent subs at a reasonable price. A huge...  \n",
      "26  b'Really tasty and very fresh food. We ordered...  \n",
      "27  b\"The food was good and the service was except...  \n",
      "28  b\"I am in Atlanta on business, and one of my c...  \n",
      "29  b\"I think their rice dishes are way better tha...  \n",
      "30  b\"We had such an amazing experience with Hilla...  \n",
      "31  b\"My first day. Had a hungry three year old. A...  \n",
      "32  b\"This restaurant is delicious! I've had Ethio...  \n",
      "33  b'3 stars just because the food is good. \\n\\nS...  \n",
      "34  b\"Finally, a non-threatening and reasonably pr...  \n",
      "35  b'Delicious shirini (sweets) and the best napo...  \n",
      "36  b'Great stay. Very clean and friendly staff. L...  \n",
      "37  b'My husband and I were referred to Sean by a ...  \n",
      "38  b'Overall can be a great experience if you\\'re...  \n",
      "39  b'Blood Orange Creamsicle you guys! Do I need ...  \n",
      "40  b'This is definitely a unique restaurant! We w...  \n",
      "41  b'This a great place to go to be social with a...  \n",
      "42  b\"Located in the German Village, this Cup o Jo...  \n",
      "43  b'Still an exceptional restaurant with several...  \n",
      "44  b\"Had a amazing dinner. Price was on point not...  \n",
      "45  b\"I highly recommend TLC Laser for anyone look...  \n",
      "46  b\"Erika was amazing! After months of trying to...  \n",
      "47  b\"Cheap glass without being a pain in the ass....  \n",
      "48  b\"Very profession insanely cheap compared to o...  \n",
      "49  b'I really like all of the Buckhead life resta...  \n",
      "50  b\"Excellent view. Nice pub menu. The Cuban was...  \n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.14284954 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.211353   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Little GEMS functions\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "\n",
    "\n",
    "outfile = open(\"business.tsv\", 'w') \n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL) \n",
    "sfile.writerow(['business_id','stars', 'review_count']) \n",
    "\n",
    "with open('yelp_dataset/yelp_academic_dataset_business.json', encoding='utf-8', errors='ignore') as f: \n",
    "    i=0\n",
    "    for line in f:  \n",
    "        row = json.loads(line)\n",
    "        if(row['review_count']>=20):\n",
    "            i+=1\n",
    "            sfile.writerow([row['business_id'], row['stars'], (row['review_count'])]) \n",
    "outfile.close() \n",
    "#loading data into dataframe using pandas\n",
    "business = pd.read_csv('business.tsv',delimiter =\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "#opens the files review stars and gets ready to implement\n",
    "outfile = open(\"review_stars.tsv\", 'w') \n",
    "#this will determine the outfile contents\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL) \n",
    "#The table coloumns\n",
    "sfile.writerow(['business_id','stars', 'text']) \n",
    "\n",
    "with open('yelp_dataset/yelp_academic_dataset_review.json', encoding='utf-8', errors='ignore') as f: \n",
    "    i = 0\n",
    "    for line in f:\n",
    "        if( i < 300):\n",
    "            i+=1\n",
    "            row = json.loads(line)\n",
    "            sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')]) \n",
    "            \n",
    "outfile.close() \n",
    "\n",
    "#loading data into dataframe using pandas\n",
    "reviews = pd.read_csv('review_stars.tsv', delimiter =\"\\t\", encoding=\"utf-8\")\n",
    "#print(business.head())\n",
    "#print(reviews.head())\n",
    "business = pd.merge(business,reviews, on=['business_id','stars'])\n",
    "business = business.drop(columns = 'review_count')\n",
    "print(business)\n",
    "\n",
    "\n",
    "\n",
    "df_review_agg = business.groupby('business_id')['text'].sum()  \n",
    "\n",
    "df_ready_for_sklearn = pd.DataFrame({'business_id': df_review_agg.index, 'all_reviews': \n",
    "df_review_agg.values}) \n",
    "\n",
    "#lab 4\n",
    "vectorizer = sk_text.TfidfVectorizer(\n",
    "                             stop_words='english',\n",
    "                             max_features = 1000,\n",
    "                             max_df = 500,\n",
    "                             min_df=2)\n",
    "\n",
    "df_all_reviews = vectorizer.fit_transform(df_ready_for_sklearn['all_reviews'])\n",
    "tfidf_data = df_all_reviews.toarray()\n",
    "#print(\"Check this out! {}\".format(tfidf_data.shape))\n",
    "#print(vectorizer.get_feature_names())\n",
    "\n",
    "#to xy x is vectorized data while y is stars\n",
    "print(tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.       0.       0.       ... 0.       0.       0.      ]\n",
      " [0.       0.       0.       ... 0.       0.       0.      ]\n",
      " [0.       0.       0.       ... 0.       0.       0.      ]\n",
      " ...\n",
      " [0.       0.       0.       ... 0.       0.211353 0.      ]\n",
      " [     nan      nan      nan ...      nan      nan      nan]\n",
      " [     nan      nan      nan ...      nan      nan      nan]]\n",
      "[5. 5. 4. 4. 4. 4. 4. 3. 3. 5. 4. 5. 4. 4. 2. 4. 4. 4. 4. 4. 4. 2. 4. 3.\n",
      " 4. 4. 4. 4. 4. 4. 5. 4. 4. 3. 4. 4. 4. 5. 3. 4. 4. 4. 4. 4. 3. 5. 5. 5.\n",
      " 5. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#to_xy accepts a dataframe\n",
    "#create a new df\n",
    "\n",
    "final_df = pd.concat([pd.DataFrame(tfidf_data),business['stars']],axis = 1)\n",
    "x,y = to_xy(final_df,'stars')\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 0s - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: nan - val_loss: nan\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-405725001d37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Final score (RMSE): {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')  \n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor], verbose=2, epochs=100)  \n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "# print out prediction\n",
    "print('Using relu and the optimizer adam')\n",
    "df_y = pd.DataFrame(y_test, columns=['actual stars'])\n",
    "df_pred = pd.DataFrame(pred, columns=['predicted stars'])\n",
    "result = pd.concat([df_y, df_pred],axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 18.3727 - val_loss: 8.0474\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 18.2922 - val_loss: 7.9967\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 18.2120 - val_loss: 7.9463\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 18.1318 - val_loss: 7.8960\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 18.0519 - val_loss: 7.8460\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 17.9722 - val_loss: 7.7961\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 17.8927 - val_loss: 7.7464\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 17.8133 - val_loss: 7.6969\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 17.7342 - val_loss: 7.6476\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 17.6553 - val_loss: 7.5985\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 17.5766 - val_loss: 7.5496\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 17.4981 - val_loss: 7.5009\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 17.4198 - val_loss: 7.4524\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 17.3417 - val_loss: 7.4041\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 17.2638 - val_loss: 7.3560\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 17.1862 - val_loss: 7.3081\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 17.1088 - val_loss: 7.2604\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 17.0316 - val_loss: 7.2130\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 16.9546 - val_loss: 7.1657\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 16.8778 - val_loss: 7.1187\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 16.8013 - val_loss: 7.0718\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 16.7250 - val_loss: 7.0252\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 16.6490 - val_loss: 6.9788\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 16.5732 - val_loss: 6.9326\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 16.4976 - val_loss: 6.8866\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 16.4222 - val_loss: 6.8409\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 16.3471 - val_loss: 6.7953\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 16.2723 - val_loss: 6.7500\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 16.1976 - val_loss: 6.7048\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 16.1232 - val_loss: 6.6599\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 16.0491 - val_loss: 6.6152\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 15.9752 - val_loss: 6.5708\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 15.9015 - val_loss: 6.5265\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 15.8281 - val_loss: 6.4825\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 15.7549 - val_loss: 6.4387\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 15.6820 - val_loss: 6.3951\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 15.6093 - val_loss: 6.3517\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 15.5369 - val_loss: 6.3085\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 15.4647 - val_loss: 6.2655\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 15.3927 - val_loss: 6.2228\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 15.3210 - val_loss: 6.1803\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 15.2495 - val_loss: 6.1380\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 15.1783 - val_loss: 6.0959\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 15.1073 - val_loss: 6.0540\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 15.0366 - val_loss: 6.0123\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 14.9661 - val_loss: 5.9709\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 14.8959 - val_loss: 5.9297\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 14.8259 - val_loss: 5.8886\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 14.7561 - val_loss: 5.8478\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 14.6866 - val_loss: 5.8072\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 14.6173 - val_loss: 5.7668\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 14.5483 - val_loss: 5.7267\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 14.4795 - val_loss: 5.6867\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 14.4109 - val_loss: 5.6470\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 14.3426 - val_loss: 5.6074\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 14.2746 - val_loss: 5.5681\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 14.2067 - val_loss: 5.5290\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 14.1392 - val_loss: 5.4901\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 14.0718 - val_loss: 5.4514\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 14.0047 - val_loss: 5.4129\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 13.9378 - val_loss: 5.3746\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 13.8712 - val_loss: 5.3365\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 13.8048 - val_loss: 5.2986\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 13.7386 - val_loss: 5.2610\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 13.6727 - val_loss: 5.2235\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 13.6070 - val_loss: 5.1862\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 13.5416 - val_loss: 5.1492\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 13.4763 - val_loss: 5.1123\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 13.4113 - val_loss: 5.0757\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 13.3466 - val_loss: 5.0392\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 13.2821 - val_loss: 5.0030\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 13.2178 - val_loss: 4.9669\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 13.1537 - val_loss: 4.9311\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 13.0899 - val_loss: 4.8954\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 13.0263 - val_loss: 4.8600\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 12.9629 - val_loss: 4.8247\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 12.8997 - val_loss: 4.7897\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 12.8368 - val_loss: 4.7548\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 12.7741 - val_loss: 4.7202\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 12.7116 - val_loss: 4.6857\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 12.6494 - val_loss: 4.6514\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 12.5874 - val_loss: 4.6174\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 12.5256 - val_loss: 4.5835\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 12.4640 - val_loss: 4.5498\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 12.4026 - val_loss: 4.5163\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 12.3415 - val_loss: 4.4830\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 12.2806 - val_loss: 4.4499\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 12.2199 - val_loss: 4.4170\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 12.1594 - val_loss: 4.3842\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 12.0992 - val_loss: 4.3517\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 12.0392 - val_loss: 4.3193\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 11.9793 - val_loss: 4.2872\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 11.9197 - val_loss: 4.2552\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 11.8604 - val_loss: 4.2234\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 11.8012 - val_loss: 4.1918\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 11.7423 - val_loss: 4.1604\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 11.6835 - val_loss: 4.1292\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 11.6250 - val_loss: 4.0981\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 11.5667 - val_loss: 4.0673\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 11.5086 - val_loss: 4.0366\n",
      "Final score (RMSE): 2.0091283321380615\n",
      "Using sigmoid and the optimizer adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual stars</th>\n",
       "      <th>predicted stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.153195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.287784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual stars  predicted stars\n",
       "0           2.0         1.153195\n",
       "1           4.0         1.287784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')  \n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor], verbose=2, epochs=100)  \n",
    "#supress statement\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "# print out prediction\n",
    "# print out prediction\n",
    "print('Using sigmoid and the optimizer adam')\n",
    "df_y = pd.DataFrame(y_test, columns=['actual stars'])\n",
    "df_pred = pd.DataFrame(pred, columns=['predicted stars'])\n",
    "result = pd.concat([df_y, df_pred],axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 16.3532 - val_loss: 24.0708\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 16.1968 - val_loss: 23.8851\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 16.0411 - val_loss: 23.7012\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 15.8861 - val_loss: 23.5184\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 15.7316 - val_loss: 23.3363\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 15.5779 - val_loss: 23.1549\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 15.4248 - val_loss: 22.9742\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 15.2723 - val_loss: 22.7940\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 15.1206 - val_loss: 22.6145\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 14.9696 - val_loss: 22.4357\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 14.8193 - val_loss: 22.2575\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 14.6697 - val_loss: 22.0801\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 14.5208 - val_loss: 21.9032\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 14.3727 - val_loss: 21.7271\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 14.2254 - val_loss: 21.5517\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 14.0788 - val_loss: 21.3770\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 13.9330 - val_loss: 21.2030\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 13.7879 - val_loss: 21.0298\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 13.6437 - val_loss: 20.8572\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 13.5002 - val_loss: 20.6854\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 13.3575 - val_loss: 20.5144\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 13.2156 - val_loss: 20.3440\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 13.0745 - val_loss: 20.1745\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 12.9341 - val_loss: 20.0056\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 12.7946 - val_loss: 19.8376\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 12.6559 - val_loss: 19.6702\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 12.5180 - val_loss: 19.5037\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 12.3809 - val_loss: 19.3379\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 12.2446 - val_loss: 19.1728\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 12.1091 - val_loss: 19.0086\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 11.9744 - val_loss: 18.8451\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 11.8406 - val_loss: 18.6825\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 11.7076 - val_loss: 18.5206\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 11.5754 - val_loss: 18.3595\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 11.4441 - val_loss: 18.1993\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 11.3137 - val_loss: 18.0399\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 11.1841 - val_loss: 17.8813\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 11.0553 - val_loss: 17.7235\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 10.9275 - val_loss: 17.5666\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 10.8005 - val_loss: 17.4105\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 10.6743 - val_loss: 17.2553\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 10.5491 - val_loss: 17.1010\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 10.4248 - val_loss: 16.9475\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 10.3013 - val_loss: 16.7950\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 10.1788 - val_loss: 16.6433\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 10.0571 - val_loss: 16.4925\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 9.9364 - val_loss: 16.3426\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 9.8166 - val_loss: 16.1936\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 9.6977 - val_loss: 16.0455\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 9.5797 - val_loss: 15.8983\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 9.4627 - val_loss: 15.7521\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 9.3465 - val_loss: 15.6068\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 9.2313 - val_loss: 15.4624\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 9.1171 - val_loss: 15.3190\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 9.0038 - val_loss: 15.1765\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 8.8914 - val_loss: 15.0350\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 8.7800 - val_loss: 14.8944\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 8.6695 - val_loss: 14.7548\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 8.5599 - val_loss: 14.6162\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 8.4513 - val_loss: 14.4785\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 8.3437 - val_loss: 14.3418\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 8.2370 - val_loss: 14.2061\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 8.1313 - val_loss: 14.0714\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 8.0266 - val_loss: 13.9376\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 7.9228 - val_loss: 13.8049\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 7.8199 - val_loss: 13.6732\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 7.7181 - val_loss: 13.5425\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 7.6171 - val_loss: 13.4127\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 7.5172 - val_loss: 13.2840\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 7.4182 - val_loss: 13.1563\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 7.3202 - val_loss: 13.0296\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 7.2232 - val_loss: 12.9040\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 7.1271 - val_loss: 12.7793\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 7.0320 - val_loss: 12.6557\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 6.9379 - val_loss: 12.5331\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 6.8447 - val_loss: 12.4116\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 6.7525 - val_loss: 12.2911\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 6.6612 - val_loss: 12.1716\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 6.5710 - val_loss: 12.0531\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 6.4816 - val_loss: 11.9357\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 6.3933 - val_loss: 11.8194\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 6.3059 - val_loss: 11.7040\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 6.2194 - val_loss: 11.5898\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 6.1340 - val_loss: 11.4765\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 6.0494 - val_loss: 11.3643\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 5.9659 - val_loss: 11.2532\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 5.8832 - val_loss: 11.1431\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 5.8016 - val_loss: 11.0341\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 5.7208 - val_loss: 10.9260\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 5.6410 - val_loss: 10.8191\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 5.5622 - val_loss: 10.7132\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 5.4843 - val_loss: 10.6083\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 5.4073 - val_loss: 10.5045\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 5.3312 - val_loss: 10.4017\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 5.2561 - val_loss: 10.3000\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 5.1819 - val_loss: 10.1993\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 5.1086 - val_loss: 10.0997\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 5.0362 - val_loss: 10.0011\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 4.9647 - val_loss: 9.9035\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 4.8941 - val_loss: 9.8070\n",
      "Final score (RMSE): 3.1316115856170654\n",
      "Using tanh and the optimizer adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual stars</th>\n",
       "      <th>predicted stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.078498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.941893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual stars  predicted stars\n",
       "0           5.0         1.078498\n",
       "1           4.0         1.941893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')  \n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor], verbose=2, epochs=100) \n",
    "#supress statement\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "# print out prediction\n",
    "print('Using tanh and the optimizer adam')\n",
    "df_y = pd.DataFrame(y_test, columns=['actual stars'])\n",
    "df_pred = pd.DataFrame(pred, columns=['predicted stars'])\n",
    "result = pd.concat([df_y, df_pred],axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
